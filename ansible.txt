===========================
Node server pre req
netplan apply (se precisar reaplicar o DHCP)

sudo su
passwd
vi /etc/ssh/sshd_config (PermitRootLogin yes)
service sshd restart

*se precisar setar IP e Hostname
echo ubuntu-<nome> > /etc/hostname
hostname -F /etc/hostname
vi etc/netplan/00-installer-config.yaml
-----
network:
  ethernets:
    enp0s3:
      addresses:
      - 192.168.1.x/24
      gateway4: 192.168.1.1
      nameservers:
        addresses:
        - 192.168.1.1
        search:
        - uz.local
  version: 2
-----
netplan apply

*Worker nodes for GlusterFS
cfdisk /dev/sdb (or vdb)
mkfs -t ext4 /dev/sdb1 (or vdb1)
mkdir /gfs
mkdir /gfs/infra
mount /dev/sdb1 /gfs/infra

make entry into /etc/fstab, so it mounts on reboot
/dev/sdb1       /gfs/infra   ext4    defaults,nofail


============================
Source script server pre req
apt install ansible
ssh-keygen
ssh-copy-id root@<node_ip>
============================
Source script server
mkdir ~/kube-cluster
cd ~/kube-cluster

nano ~/kube-cluster/hosts (alterar IPs)

ansible-playbook -i hosts ~/kube-cluster/main/initial.yml
ansible-playbook -i hosts ~/kube-cluster/kubernetes/kube-dependencies.yml
ansible-playbook -i hosts ~/kube-cluster/kubernetes/master.yml

ssh ubuntu@master_ip
kubectl get nodes

ansible-playbook -i hosts ~/kube-cluster/kubernetes/workers.yml

ssh ubuntu@master_ip
kubectl get nodes

ansible-playbook -i hosts ~/kube-cluster/gluster/glusterfs.yml
